# .github/workflows/enhanced-classification-workflow.yml
name: Enhanced AI Classification Workflow
# Phase 2: Advanced Issue Classification Engine
# Processes CodeRabbit findings with AI-powered classification

on:
  pull_request_review:
    types: [submitted]
  issue_comment:
    types: [created, edited]
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Run in test mode'
        required: false
        default: 'false'
        type: boolean
      classification_only:
        description: 'Only run classification (no remediation)'
        required: false
        default: 'false'
        type: boolean

# P0 FIX: Prevent CI recursion and race conditions
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  GH_TOKEN: ${{ secrets.HX_COMMIT_TOKEN }}
  PYTHON_VERSION: '3.11'
  CLASSIFICATION_CONFIG: 'scripts/automation/config/classification_config.yml'

# Minimal permissions for security (principle of least privilege)
permissions:
  contents: read

jobs:
  # Job 1: Enhanced Issue Detection and Classification
  enhanced-classification:
    name: AI-Powered Issue Classification
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      pull-requests: write
      statuses: write
    # P0 FIX: Enhanced bot detection to prevent CI recursion
    if: >
      github.event.review.body contains 'coderabbit' || github.event.comment.body contains 'coderabbit' || github.event_name == 'workflow_dispatch'

    outputs:
      issues-detected: ${{ steps.classify.outputs.issues-detected }}
      critical-count: ${{ steps.classify.outputs.critical-count }}
      auto-remediable-count: ${{ steps.classify.outputs.auto-remediable-count }}
      classification-report: ${{ steps.classify.outputs.classification-report }}

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt || echo 'No requirements.txt found'
        # P0 FIX: Pin Python dependencies for stable CI runs
        pip install scikit-learn==1.3.2 numpy==1.24.4 pandas==2.1.4 pyyaml==6.0.1 requests==2.31.0
        pip install nltk==3.8.1 textblob==0.17.1  # For advanced NLP features

    - name: Configure GitHub CLI
      if: github.event.pull_request.head.repo.fork == false
      shell: bash
      run: |
        gh auth status

    - name: Validate Changed Paths (Allowlist Enforcement)
      run: |
        echo '=== Validating Changed Paths Against Allowlist ===='
        git fetch origin

        # Get changed files for this PR/push
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          changed=$(git diff --name-only origin/${{ github.event.pull_request.base.ref }}...HEAD)
        else
          changed=$(git diff --name-only origin/main...HEAD)
        fi

        echo "Files changed in this automation run:"
        echo "$changed"

        # Define allowlisted paths
        allowlist_pattern='^(roles/|playbooks/|inventories/|scripts/|tests/|docs/|Makefile|README\.md)$'

        # Check for non-allowlisted paths
        violations=$(echo "$changed" | grep -v '^$' | grep -Ev "$allowlist_pattern" || true)

        if [ -n "$violations" ]; then
          echo "❌ ERROR: Non-allowlisted paths modified by automation:"
          echo "$violations"
          echo ""
          echo "Allowed paths for automation:"
          echo "  - roles/"
          echo "  - playbooks/"
          echo "  - inventories/"
          echo "  - scripts/"
          echo "  - tests/"
          echo "  - docs/"
          echo "  - Makefile"
          echo "  - README.md"
          echo ""
          echo "Prohibited paths (manual changes only):"
          echo "  - .github/workflows/"
          echo "  - secrets/"
          echo "  - .evidence/"
          echo "  - .gitmodules"
          exit 1
        fi

        echo "✅ All changed paths are allowlisted for automation"

    - name: Initialize ML models
      id: init-models
      run: |
        echo '=== Initializing AI Classification Models ===='
        python -c "
        import os
        import sys
        sys.path.append('scripts/automation')
        from classification.ai_classifier import AIIssueClassifier

        # Initialize classifier and check model availability
        classifier = AIIssueClassifier()
        print(f'ML models available: {hasattr(classifier, \"ml_available\") and classifier.ml_available}')
        print('Classification engine initialized successfully')
        "

    - name: Extract CodeRabbit comments
      id: extract
      run: |
        echo '=== Extracting CodeRabbit Comments ===='

        # Get PR or issue information
        if [ "${{ github.event_name }}" = "pull_request_review" ]; then
          PR_NUMBER="${{ github.event.pull_request.number }}"
          COMMENT_BODY="${{ github.event.review.body }}"
        elif [ "${{ github.event_name }}" = "issue_comment" ]; then
          PR_NUMBER="${{ github.event.issue.number }}"
          COMMENT_BODY="${{ github.event.comment.body }}"
        elif [ "${{ github.event_name }}" = "pull_request" ]; then
          PR_NUMBER="${{ github.event.pull_request.number }}"
          COMMENT_BODY="PR synchronization event"
        else
          PR_NUMBER="0"
          COMMENT_BODY="Manual workflow dispatch"
        fi

        echo "pr-number=$PR_NUMBER" >> $GITHUB_OUTPUT
        echo "Processing PR #$PR_NUMBER"

        # Extract all CodeRabbit comments from the PR
        python scripts/automation/parse_coderabbit_comments.py \
          --pr-number "$PR_NUMBER" \
          --repository "${{ github.repository }}" \
          --output-file "coderabbit_comments.json" \
          --include-resolved false \
          --format json

        # Check if comments were found
        if [ -f "coderabbit_comments.json" ]; then
          COMMENT_COUNT=$(jq length coderabbit_comments.json)
          echo "comments-found=$COMMENT_COUNT" >> $GITHUB_OUTPUT
          echo "Found $COMMENT_COUNT CodeRabbit comments"
        else
          echo "comments-found=0" >> $GITHUB_OUTPUT
          echo "No CodeRabbit comments found"
        fi

    - name: AI-Powered Classification
      id: classify
      if: steps.extract.outputs.comments-found > 0
      run: |
        echo '=== Running AI-Powered Classification ===='

        # Run advanced classification on extracted comments
        python -c "
        import json
        import sys
        import os
        from datetime import datetime

        sys.path.append('scripts/automation')
        from classification.ai_classifier import AIIssueClassifier

        # Initialize classifier
        classifier = AIIssueClassifier()

        # Load extracted comments
        with open('coderabbit_comments.json', 'r') as f:
            comments = json.load(f)

        print(f'Classifying {len(comments)} comments...')

        # Classify each comment
        classifications = []
        stats = {
            'critical': 0, 'high': 0, 'medium': 0, 'low': 0,
            'auto_remediable': 0, 'manual_review': 0
        }

        for i, comment in enumerate(comments):
            try:
                # Extract comment details
                text = comment.get('body', '')
                file_path = comment.get('path', '')
                suggested_fix = comment.get('suggested_change', '')

                # Classify the issue
                result = classifier.classify_issue(text, file_path, suggested_fix)

                # Convert to dict for JSON serialization
                classification = {
                    'comment_id': comment.get('id', i),
                    'file_path': file_path,
                    'line_number': comment.get('line', 0),
                    'original_text': text,
                    'suggested_fix': suggested_fix,
                    'classification': {
                        'severity': result.severity,
                        'category': result.category,
                        'complexity': result.complexity,
                        'confidence_score': result.confidence_score,
                        'reasoning': result.reasoning,
                        'auto_remediable': result.auto_remediable,
                        'priority_score': result.priority_score,
                        'estimated_effort_hours': result.estimated_effort_hours,
                        'required_skills': result.required_skills,
                        'risk_level': result.risk_level,
                        'business_impact': result.business_impact
                    },
                    'timestamp': datetime.now().isoformat()
                }

                classifications.append(classification)

                # Update statistics
                stats[result.severity] += 1
                if result.auto_remediable:
                    stats['auto_remediable'] += 1
                else:
                    stats['manual_review'] += 1

                print(f'Classified comment {i+1}/{len(comments)}: {result.severity}/{result.category} (confidence: {result.confidence_score:.2f})')

            except Exception as e:
                print(f'Error classifying comment {i}: {e}')
                continue

        # Save classifications
        with open('issue_classifications.json', 'w') as f:
            json.dump(classifications, f, indent=2)

        # Generate summary report
        summary = {
            'total_issues': len(classifications),
            'statistics': stats,
            'timestamp': datetime.now().isoformat(),
            'classification_engine': 'AI-Powered Hybrid Classifier v2.0'
        }

        with open('classification_summary.json', 'w') as f:
            json.dump(summary, f, indent=2)

        print(f'Classification complete: {len(classifications)} issues processed')
        print(f'Statistics: {stats}')
        "

        # Set outputs for next jobs
        if [ -f "classification_summary.json" ]; then
          TOTAL_ISSUES=$(jq -r '.total_issues' classification_summary.json)
          CRITICAL_COUNT=$(jq -r '.statistics.critical' classification_summary.json)
          AUTO_REMEDIABLE=$(jq -r '.statistics.auto_remediable' classification_summary.json)

          echo "issues-detected=$TOTAL_ISSUES" >> $GITHUB_OUTPUT
          echo "critical-count=$CRITICAL_COUNT" >> $GITHUB_OUTPUT
          echo "auto-remediable-count=$AUTO_REMEDIABLE" >> $GITHUB_OUTPUT
          echo "classification-report=classification_summary.json" >> $GITHUB_OUTPUT

          echo "Classification Results:"
          echo "- Total Issues: $TOTAL_ISSUES"
          echo "- Critical Issues: $CRITICAL_COUNT"
          echo "- Auto-remediable: $AUTO_REMEDIABLE"
        fi

    - name: Generate Classification Visualization
      if: steps.classify.outputs.issues-detected > 0
      run: |
        echo '=== Generating Classification Visualization ===='

        # Create Mermaid diagram for classification results
        python -c "
        import json

        # Load classification results
        with open('issue_classifications.json', 'r') as f:
            classifications = json.load(f)

        with open('classification_summary.json', 'r') as f:
            summary = json.load(f)

        # Generate Mermaid flowchart
        mermaid = '''```mermaid
        flowchart TD
            A[CodeRabbit Comments: {total}] --> B[AI Classification Engine]
            B --> C[Severity Analysis]
            B --> D[Category Analysis]
            B --> E[Complexity Analysis]

            C --> C1[Critical: {critical}]
            C --> C2[High: {high}]
            C --> C3[Medium: {medium}]
            C --> C4[Low: {low}]

            D --> D1[Security: {security}]
            D --> D2[Configuration: {config}]
            D --> D3[Quality: {quality}]
            D --> D4[Documentation: {docs}]
            D --> D5[Performance: {perf}]
            D --> D6[Other: {other}]

            E --> E1[Auto-Remediable: {auto}]
            E --> E2[Manual Review: {manual}]

            E1 --> F[Cursor AI Integration]
            E2 --> G[Human Review Queue]

            style C1 fill:#ff6b6b
            style C2 fill:#ffa726
            style C3 fill:#ffeb3b
            style C4 fill:#66bb6a
            style E1 fill:#4caf50
            style E2 fill:#2196f3
        ```'''.format(
            total=summary['total_issues'],
            critical=summary['statistics']['critical'],
            high=summary['statistics']['high'],
            medium=summary['statistics']['medium'],
            low=summary['statistics']['low'],
            security=len([c for c in classifications if c['classification']['category'] == 'security']),
            config=len([c for c in classifications if c['classification']['category'] == 'configuration']),
            quality=len([c for c in classifications if c['classification']['category'] == 'quality']),
            docs=len([c for c in classifications if c['classification']['category'] == 'documentation']),
            perf=len([c for c in classifications if c['classification']['category'] == 'performance']),
            other=len([c for c in classifications if c['classification']['category'] not in ['security', 'configuration', 'quality', 'documentation', 'performance']]),
            auto=summary['statistics']['auto_remediable'],
            manual=summary['statistics']['manual_review']
        )

        with open('classification_diagram.md', 'w') as f:
            f.write('# AI Classification Results\\n\\n')
            f.write(mermaid)
            f.write('\\n\\n## Summary\\n\\n')
            f.write(f'- **Total Issues Processed:** {summary[\"total_issues\"]}\\n')
            f.write(f'- **Critical Issues:** {summary[\"statistics\"][\"critical\"]}\\n')
            f.write(f'- **Auto-Remediable Issues:** {summary[\"statistics\"][\"auto_remediable\"]}\\n')
            f.write(f'- **Manual Review Required:** {summary[\"statistics\"][\"manual_review\"]}\\n')

        print('Classification visualization generated')
        "

    - name: Upload classification artifacts
      if: steps.classify.outputs.issues-detected > 0
      uses: actions/upload-artifact@v4
      with:
        name: classification-results-${{ github.run_number }}
        path: |
          issue_classifications.json
          classification_summary.json
          classification_diagram.md
          coderabbit_comments.json
        retention-days: 30

  # Job 2: Create GitHub Issues with Enhanced Classification
  create-enhanced-issues:
    name: Create Enhanced GitHub Issues
    runs-on: ubuntu-latest
    needs: enhanced-classification
    timeout-minutes: 30
    permissions:
      issues: write
    if: needs.enhanced-classification.outputs.issues-detected > 0 && github.event.pull_request.head.repo.fork == false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Configure GitHub CLI
      shell: bash
      run: |
        gh auth status

    - name: Download classification results
      uses: actions/download-artifact@v4
      with:
        name: classification-results-${{ github.run_number }}

    - name: Create enhanced GitHub issues
      run: |
        echo '=== Creating Enhanced GitHub Issues ===='

        # P0 FIX: Enhanced issue creation with deduplication
        python scripts/automation/create_github_issues.py \
          --classification-file "issue_classifications.json" \
          --repository "${{ github.repository }}" \
          --pr-number "${{ github.event.pull_request.number }}" \
          --deduplicate true \
          --label-prefix "ai-classified" \
          --assign-owner true

  # Job 3: Automated Remediation with Cursor
  auto-remediation:
    name: Automated Remediation
    runs-on: ubuntu-latest
    needs: create-enhanced-issues
    timeout-minutes: 60
    permissions:
      pull-requests: write
      contents: write
    if: needs.enhanced-classification.outputs.auto-remediable-count > 0 && github.event.pull_request.head.repo.fork == false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Download classification results
      uses: actions/download-artifact@v4
      with:
        name: classification-results-${{ github.run_number }}

    - name: Run Cursor AI Remediation
      run: |
        echo '=== Running Cursor AI Remediation ===='
        python scripts/automation/cursor/cursor_ai_engine.py \
          --issues-file "issue_classifications.json" \
          --config-file "scripts/automation/config/cursor_config.yml" \
          --output-file "remediation_results.json" \
          --auto-commit true \
          --pr-number "${{ github.event.pull_request.number }}"

    - name: Upload remediation artifacts
      uses: actions/upload-artifact@v4
      with:
        name: remediation-results-${{ github.run_number }}
        path: remediation_results.json
        retention-days: 30

  # Job 4: Generate Enhanced Summary Report
  generate-summary:
    name: Generate Summary Report
    runs-on: ubuntu-latest
    needs: [enhanced-classification, auto-remediation]
    timeout-minutes: 30
    permissions:
      pull-requests: write
    if: always() && needs.enhanced-classification.outputs.issues-detected > 0 && github.event.pull_request.head.repo.fork == false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Download classification results
      uses: actions/download-artifact@v4
      with:
        name: classification-results-${{ github.run_number }}

    - name: Download remediation results
      uses: actions/download-artifact@v4
      with:
        name: remediation-results-${{ github.run_number }}
        path: .
        if-no-files-found: error

    - name: Generate enhanced summary report
      run: |
        echo '=== Generating Enhanced Summary Report ===='

        # P0 FIX: Enhanced progress tracking with accurate completion rates
        python scripts/automation/generate_summary_report.py \
          --classification-file "issue_classifications.json" \
          --remediation-file "remediation_results.json" \
          --workflow-run-id "${{ github.run_id }}" \
          --enhanced-analytics true \
          --include-ml-metrics true \
          --generate-recommendations true \
          --output-format markdown \
          --track-all-states true \
          --accurate-completion-rates true

        # Create PR comment with enhanced summary
        if [ -f "enhanced_summary_report.md" ]; then
          gh pr comment ${{ github.event.pull_request.number }} \
            --body-file enhanced_summary_report.md || \
          echo "Could not create PR comment (may not be a PR event)"
        fi

    - name: Upload enhanced summary
      uses: actions/upload-artifact@v4
      with:
        name: enhanced-summary-${{ github.run_number }}
        path: |
          enhanced_summary_report.md
          classification_metrics.json
        retention-days: 90

  # Job 5: Quality Gates and Validation
  quality-gates:
    name: AI Classification Quality Gates
    runs-on: ubuntu-latest
    needs: enhanced-classification
    timeout-minutes: 15
    permissions:
        statuses: write
    if: needs.enhanced-classification.outputs.critical-count > 0 && github.event.pull_request.head.repo.fork == false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Download classification results
      uses: actions/download-artifact@v4
      with:
        name: classification-results-${{ github.run_number }}

    - name: Validate critical issues
      run: |
        echo '=== Validating Critical Issues ===='

        CRITICAL_COUNT="${{ needs.enhanced-classification.outputs.critical-count }}"

        if [ "$CRITICAL_COUNT" -gt 0 ]; then
          echo "⚠️ CRITICAL ISSUES DETECTED: $CRITICAL_COUNT"
          echo "Manual review required before merge"

          # Create blocking status check
          gh api repos/${{ github.repository }}/statuses/${{ github.sha }} \
            --method POST \
            --field state='failure' \
            --field target_url='${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}' \
            --field description="$CRITICAL_COUNT critical issues require manual review" \
            --field context='ai-classification/critical-issues'

          exit 1
        else
          echo "✅ No critical issues detected"

          # Create success status check
          gh api repos/${{ github.repository }}/statuses/${{ github.sha }} \
            --method POST \
            --field state='success' \
            --field target_url='${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}' \
            --field description='No critical issues detected' \
            --field context='ai-classification/critical-issues'
        fi

